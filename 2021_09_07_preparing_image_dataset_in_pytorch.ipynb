{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-09-07-preparing-image-dataset-in-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnyVeyExljyoRw7BYCMhxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salfaris/notebooks/blob/main/2021_09_07_preparing_image_dataset_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQYt4VqdmOoG"
      },
      "source": [
        "# Preparing Image Dataset for Neural Networks in PyTorch\n",
        "\n",
        "This notebook is a simplified version of my blog post which you can find [here](https://salfaris.me/blog/2021-09-07-preparing-image-dataset-for-neural-networks-in-pytorch.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTbnTFbBl1RC"
      },
      "source": [
        "### PyTorch and Torchvision\n",
        "\n",
        "Start by importing `torch` and `torchvision`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYv2f1ullmrU",
        "outputId": "edafd2b0-3ac7-4c89-ecb1-401019fb037f"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "torch.manual_seed(44)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f157fcf0910>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthPzB5Jl_GM"
      },
      "source": [
        "### üëú Fashion MNIST dataset and composing transformations\n",
        "\n",
        "We will apply two simple transformations to our image:\n",
        "\n",
        "1. Converting the images to a PyTorch `tensor` ‚Äì by using `transforms.ToTensor()`.\n",
        "2. Normalize the channel of the resulting tensor ‚Äì by using `transforms.Normalize()`.\n",
        "\n",
        "We can then compose these transformations using `transforms.Compose()` as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_5pjPXl6ou"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5)),\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PG49WTRmI4k"
      },
      "source": [
        "### üíæ From dataset to Dataloader\n",
        "\n",
        "The next step is to finally fetch the dataset, passing our transform above as an argument. We then feed into PyTorch's `DataLoader` object to get features like batching, shuffling and loading data in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4GdSaymlpo"
      },
      "source": [
        "trainset = datasets.FashionMNIST(root='./data', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "testset = datasets.FashionMNIST(root='./data', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CYwY_mWmtw8"
      },
      "source": [
        "### üïµÔ∏è Inspecting the dataset in DataLoader form\n",
        "\n",
        "Once we have the dataset in DataLoader form, we can start inspecting our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Me5yl6lnA_l",
        "outputId": "0af0da66-6867-4444-c271-7174e90e08ba"
      },
      "source": [
        "print(\"Train shape:\", trainloader.dataset.data.shape)\n",
        "print(\"Test shape:\", testloader.dataset.data.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: torch.Size([60000, 28, 28])\n",
            "Test shape: torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVVzj447nDDd",
        "outputId": "aa5040cd-789b-43d4-c8c0-151317f8241e"
      },
      "source": [
        "print(\"Train batch size:\", trainloader.batch_size)\n",
        "print(\"Test batch size:\", testloader.batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batch size: 64\n",
            "Test batch size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAjOi5DSnEie",
        "outputId": "392f3959-3910-45f9-c931-5fe6209d6727"
      },
      "source": [
        "print(\"Sampler:\", trainloader.sampler)\n",
        "print(\"Collate function:\", trainloader.collate_fn)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampler: <torch.utils.data.sampler.RandomSampler object at 0x7f157ca69750>\n",
            "Collate function: <function default_collate at 0x7f157ee848c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8OumEpxnG_3"
      },
      "source": [
        "We can also plot an example image. Let's plot the first image from the first batch in `trainloader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlXFIhsonmJ3"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "H51-Lr0sni3B",
        "outputId": "a007df1c-72ec-451a-bb7c-09c1a6a989a1"
      },
      "source": [
        "images, labels = next(iter(trainloader))  # Gets a batch of 64 images in the training set\n",
        "first_image = images[0]  # Get the first image out of the 64 images.\n",
        "\n",
        "plt.imshow(first_image.numpy().squeeze(), cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}